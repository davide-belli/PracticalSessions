{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ComputerVisionPart1_start.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi1dtiTtK1Ov",
        "colab_type": "text"
      },
      "source": [
        "## EEML2019: ConvNets and Computer Vision Tutorial (PART I)\n",
        "\n",
        "### Supervised classification, overfitting and inductive biases in convnets, and how to improve models through self-supervision\n",
        "\n",
        "* Exercise 1: Implement and train a Resnet-50 classifier using supervised learning; enable/disable batch norm updates to see the effect.\n",
        "* Exercise 2: Inductive biases in convnets; comparison with MLP.\n",
        "* Exercise 3: Overfitting and regularization using weight decay.\n",
        "* Exercise 4: Enable self-supervised learning using data augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ho_PioVRL_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Don't forget to select GPU runtime environment in Runtime -> Change runtime type\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Plotting library.\n",
        "from matplotlib import pyplot as plt\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "\n",
        "import collections\n",
        "import enum\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEjvs0YDUS-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reset graph\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P65vVFkUbTu",
        "colab_type": "text"
      },
      "source": [
        "## Download dataset to be used for training and testing\n",
        "* Cifar-10 equivalent of MNIST for natural RGB images\n",
        "\n",
        "* 60000 32x32 colour images in 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
        "\n",
        "* train: 50000; test: 10000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEEkhc5KRa8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "# (down)load dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Check sizes of tensors\n",
        "print ('Size of training images')\n",
        "print (train_images.shape)\n",
        "print ('Size of training labels')\n",
        "print (train_labels.shape)\n",
        "print ('Size of test images')\n",
        "print (test_images.shape)\n",
        "print ('Size of test labels')\n",
        "print (test_labels.shape)\n",
        "\n",
        "assert train_images.shape[0] == train_labels.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vMPjp0UU4Mx",
        "colab_type": "text"
      },
      "source": [
        "## Display the images\n",
        "The gallery function below shows sample images from the data, together with their labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy0BWFwFUQ0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_IMAGES = 10\n",
        "def gallery(images, label, title='Input images'):  \n",
        "  class_dict = [u'airplane', u'automobile', u'bird', u'cat', u'deer', u'dog', u'frog', u'horse', u'ship', u'truck']\n",
        "  num_frames, h, w, num_channels = images.shape\n",
        "  num_frames = min(num_frames, MAX_IMAGES)\n",
        "  ff, axes = plt.subplots(1, num_frames,\n",
        "                          figsize=(num_frames, 1),\n",
        "                          subplot_kw={'xticks': [], 'yticks': []})\n",
        "  for i in range(0, num_frames):\n",
        "    if num_channels == 3:\n",
        "      axes[i].imshow(np.squeeze(images[i]))\n",
        "    else:\n",
        "      axes[i].imshow(np.squeeze(images[i]), cmap='gray')\n",
        "    axes[i].set_title(class_dict[label[i][0]])\n",
        "    plt.setp(axes[i].get_xticklabels(), visible=False)\n",
        "    plt.setp(axes[i].get_yticklabels(), visible=False)\n",
        "  ff.subplots_adjust(wspace=0.1)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kGaRa23RfjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gallery(train_images, train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pgKO2uEU_tn",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the data for training and testing\n",
        "* for training, we use stochastic optimizers (e.g. SGD, Adam), so we need to sample at random mini-batches from the training dataset\n",
        "* for testing, we iterate sequentially through the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7DbXWyoRjO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define dimension of the batches to sample from the datasets\n",
        "BATCH_SIZE_TRAIN = 100 #@param\n",
        "BATCH_SIZE_TEST = 100 #@param\n",
        "\n",
        "# create Dataset objects using the data previously downloaded\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "# we shuffle the data and sample repeatedly batches for training\n",
        "batched_dataset_train = dataset_train.shuffle(100000).repeat().batch(BATCH_SIZE_TRAIN)\n",
        "# create iterator to retrieve batches\n",
        "iterator_train = batched_dataset_train.make_one_shot_iterator()\n",
        "# get a training batch of images and labels\n",
        "(batch_train_images, batch_train_labels) = iterator_train.get_next()\n",
        "\n",
        "# check that the shape of the training batches is the expected one\n",
        "print ('Shape of training images')\n",
        "print (batch_train_images)\n",
        "print ('Shape of training labels')\n",
        "print (batch_train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpHYjHEiRmvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we do the same for test dataset\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "batched_dataset_test = dataset_test.repeat().batch(BATCH_SIZE_TEST)\n",
        "iterator_test = batched_dataset_test.make_one_shot_iterator() \n",
        "(batch_test_images, batch_test_labels) = iterator_test.get_next()\n",
        "print ('Shape of test images')\n",
        "print (batch_test_images)\n",
        "print ('Shape of test labels')\n",
        "print (batch_test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6jMNp1KRqW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Squeeze labels and convert from uint8 to int32 - required below by the loss op\n",
        "batch_test_labels = tf.cast(tf.squeeze(batch_test_labels), tf.int32)\n",
        "batch_train_labels = tf.cast(tf.squeeze(batch_train_labels), tf.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q9xIZOJEiiU",
        "colab_type": "text"
      },
      "source": [
        "## General setting; use the options below to switch between exercises."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b8dDvmpEgwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = \"mlp\" #@param['resnet_v2','mlp']\n",
        "flag_batch_norm = 'OFF' #@param['ON', 'OFF']\n",
        "flag_permute = \"False\" #@param['True', 'False']\n",
        "flag_regularize = \"False\" #@param['True', 'False']\n",
        "flag_selfsup = \"False\" #@param['True', 'False']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9W8ggEBVlcG",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess input for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDTKjPO_4GLG",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title 32x32 permutation list (for Exercise 3)\n",
        "def get_permutation_cifar10():\n",
        "  p = tf.constant([ 273,  746,  984,  197,  597,  519,  757,  113, 1009,  470,  321,\n",
        "        552,  585,  246,  229,  569,  773,    6,  955,  379,  847,  548,\n",
        "        148,  503,   27,  132, 1014,   82,  101,  260,  923,   53,  842,\n",
        "        635,  203,  912,  439,  487,  162,  832,  395,  311,  593,   33,\n",
        "        988,  856,  183,  215,  264,  699,  826,  692,  560,  124,  126,\n",
        "        948,  708,   41,  368,  484,  467,  267,  731,   17,   73,   14,\n",
        "        521,  240,  296,  846,   43,  779,  629,  640,  874,  268,  150,\n",
        "        586,   56,  756,  769,  808,  382,  354,   95,  283,  900,  970,\n",
        "        775,  432,  178,  998,  271,  118,  563,  445,  946,  261,  518,\n",
        "        723,  725,  449,  595,  617,  935,  607,  400,  697,   96,  786,\n",
        "        656,  138,  343,  653,  175,  993,  433,  681,  654,  574,  322,\n",
        "        918,  831,  754,  381,   12,  797,  338,  182,  695,  829,  927,\n",
        "        556, 1008,  491,  512,  717,  224,  303,  496, 1002,  693,  140,\n",
        "        599,  332,  758,  465,   80,  501,  690, 1022,  422,  211,  331,\n",
        "        926,  849,  313,  583,  128,  776,  168,  463,  201, 1018,  334,\n",
        "        228,  643,  514,  934,  106,  799,  713,  507,  543,  703,  299,\n",
        "         74,  263,  710,  622,  486,  344,  210,  687,  537,  362,  858,\n",
        "        898,  688,  320,   91,  403,  778,  534,  674,  783,  284,  968,\n",
        "        807,  724,  549,  184,  605,   15,    8,  535,   85,  495,  774,\n",
        "        701,  848,  416,  642,  553,  897,  989,  370,  942,  571,  489,\n",
        "        891,  388,  171,  761,  475,  844,  397,  227,  753,  278,  855,\n",
        "        938,  794,  155,  748, 1017,  941,  745,  437,  414,  181,  759,\n",
        "        234,  143,  554,  762,   46,  476,  417,  911, 1007,  882,  716,\n",
        "        336,  117,   47,  977,  602,  837,  525,  880,  718,  660,  760,\n",
        "        451,  142,  609,  405,  455,  315,  394,  987,   36,  389,  719,\n",
        "        715,  386,  393,  446,  109,  658,  612,  685,  577, 1015,  967,\n",
        "        641,  770,  510,  704,  793,  892,  275,  904,  335,  893,  259,\n",
        "        307,  903,  985,  435,  712,  326,  232, 1021,  237,  827, 1005,\n",
        "        172, 1000,  675,   84,  670,  963,  434,  485,   68,  677,  415,\n",
        "        492,  947,  859,  732,  810,  366,  557,   22,  824,  765,  722,\n",
        "        902,  950,  579,  288,  308,   48,  198, 1003,  481,  604,  139,\n",
        "       1001,  647,  115,  618,  243,  466,  107,  795,  440,  152,  885,\n",
        "        200,  230,   83,  821,  755,   10,  144,  749,  528,  494,  199,\n",
        "        546,  282,  921,  223,  828,  962,  346,  925,  352,  421, 1023,\n",
        "        763,  424,  894,  328,  290,   13,   62,  129,  156,  820,  436,\n",
        "        871,  252,  359,  538,   35,  459,  226,  657,  401,  191,  483,\n",
        "        187,  242,  680,  646,  473,  802,    4,  581,  130,  666,  709,\n",
        "        889,    7,  864,  236,  991,  450,  532,  667,   70, 1011,  410,\n",
        "        907,  266,  914,  189,  943,  796,  649,  990,  257,  937,  700,\n",
        "        500,  188,  813,  809,  634,  789,   25,  517,  573,  104,  387,\n",
        "        673,  966,  638,  845,  540, 1006,  910,  249,  610,  110,  480,\n",
        "        663,    9,  225,  339,  398,  976,  131,  372,  628,  875,  174,\n",
        "        488,  908,   79,  766,  310,  468,  691,  425,  289,  616,  309,\n",
        "        915,  570,  636,  768,  591,  956,  464,  412,  120,  958,  939,\n",
        "        782,  652,  541,  971,  100,  280,  721,  423,  430,  442,  506,\n",
        "        160,  502,  333,  615,  399,   57,  250,  384,  959, 1012,   71,\n",
        "        103,  429,  411,   59,  862,  887,  980,  529,  630,  444,  785,\n",
        "        625,  916,  883,  901,  983,  852,  179,  747,  801,  218,  627,\n",
        "        408,  443,  830,  305,  733,  509,  274,  682,  884,  584,  358,\n",
        "        536,  739,  369,  933,  221,  247,  676,  982,  206,    1,  438,\n",
        "        265,  954,  866,  672,  287,   26,   39,  606,  479,  102,  291,\n",
        "         88,  205,   61,  931,  127,  351, 1004,  477,  655,  865,  355,\n",
        "         67,   37,  735,  458,  454,  737,  873,  909,  173,  231,  158,\n",
        "        555,  825,  945,  930,  337,  644,  505,  233,  730,  431, 1020,\n",
        "        530,  580,  312,  720,  441,  550,  952,  367,  513,   50,  371,\n",
        "         34,   45,  705,  153,  122,  209,   51,  870,  216,  185,  611,\n",
        "        327,  815,  899,  603,  428, 1010,   42,  669, 1019,  601,  788,\n",
        "        620,  771,  886,  116,  293,  986,  363,  834,  881,   81,   90,\n",
        "        474,   94,  302,   31,  863,  317,  619,  471,   86,  869,   64,\n",
        "        994,  683,   20,  330, 1013,  472,  650,  714,  380,  812,  853,\n",
        "        196,  272,  736,  349,   75,  169,   28,  340,  163,  151,  979,\n",
        "        798,  582,  559,  376,   24,  539,  818,  176,  207,  992,  600,\n",
        "        975,  767,  867,  592,  978,  726,  277,  511,   98,  850,  498,\n",
        "        668,  298,  292,  792,  523,  598,  742,  623,  426,  841,  361,\n",
        "        121,  157,  964,  146,  490,  791,  780,  360,  679,   38,  222,\n",
        "        419,  192,  587,   30,   77,  702,  235,  953,  997,  318,  751,\n",
        "          2,  396,  542,  661,  499,   29,   69,  180,  621,  217,  588,\n",
        "        972,   58,   60,  164,  840,  772,  545,  452,  170,  951,  752,\n",
        "        281,  478,  711,  648,  575,  787,  213,  345,   19,  803,  190,\n",
        "        527,  508,  149,  323,  624,  404,  817,  895,  420,  256,  413,\n",
        "        626,  134,  390,  614,  342,  565,  238,  949,  241,  781,  590,\n",
        "        533,  659,  365,  561,  112,  248,  357,  566,  407,  253,  913,\n",
        "        461,  957,  932,  594,  255,  406,  784,  750,    3,  356,  141,\n",
        "         97,   92,  919,  522,  734,  325,   54,  877,  738,  456,  133,\n",
        "        917,  374,   66,  729,  835,  114,  833,  214,  504,  383,  631,\n",
        "        347,  686,  905,  578,  613,  239,  806,  645,  790,  764,  427,\n",
        "        651,  568,   87,  119,   63,   65,  202,  890,  940,  928,  286,\n",
        "        409,  662,  551,   49,  251,  572,  632,    5,  524,  515,  888,\n",
        "        608,  208,  329,   18,  516,  350,  295,  448,  385,  678,  936,\n",
        "        896,  258,  204,  276,  177,  854,   72,  341,   16,  974,  836,\n",
        "        851,  497,  316,  805,  262,  544,  981,  838,  843,  526,  707,\n",
        "        348,  254,  447,  520,  453,  270,  304,  558,  462,  418,  279,\n",
        "         99,  353,  314,  306,  564,  219,  167,  186,  297,  706,    0,\n",
        "        804,   89,  878,   11,  816,  402,  868,  531,   78,  728,  373,\n",
        "        562,  684,  944,  860,  876,  194,  195,  906,  973,  294,  960,\n",
        "        567,  698,  378,  589,   40,  220,  493,  460,  929,  861,  823,\n",
        "         76,  105, 1016,  839,  639,  324,  166,  740,   23,   52,  161,\n",
        "        319,  996,  392,  135,  111,  391,  547,  145,  961,  999,  123,\n",
        "        744,  364,  147,  469,  811,  125,  159,  664,  965,   93,  727,\n",
        "        245,  814,  696,  377,   21,  665,  694,  920,  857,   55,  879,\n",
        "        269,  285,  671,  165,  924,  193,  244,  969,  800,  457,  922,\n",
        "        741,  375,  995,  482,  576,  108,  743,  689,  300,   44,   32,\n",
        "        136,  872,  596,  637,  137,  819,  154,  633,  777,  301,  212,\n",
        "        822])\n",
        "\n",
        "  return p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsky7B6aRvDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data augmentation\n",
        "# - scale image to [-1 , 1]\n",
        "# - during training: apply horizontal flip randomly\n",
        "# - random crop after padding\n",
        "# - apply optional data augmentation (permutation, rotation)\n",
        "\n",
        "def train_image_preprocess(h, w, num_transf=None):\n",
        "  def fn(image):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    image = image * 2 - 1\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    # Data augmentation: pad images and randomly sample a (h, w) patch.\n",
        "    image = tf.pad(image, [[0, 0], [4, 4], [4, 4], [0, 0]], mode='REFLECT')\n",
        "    image = tf.random_crop(image, size=(BATCH_SIZE_TRAIN, h, w, 3))\n",
        "\n",
        "    # Exercise 2: permuted Cifar10; scramble the images using a fixed permutation\n",
        "    if flag_permute:\n",
        "      ################\n",
        "      # YOUR CODE HERE  reshape image 2D -> 1D array using tf.reshape\n",
        "      p = get_permutation_cifar10()\n",
        "      ################\n",
        "      # YOUR CODE HERE  permute pixels according to permutation p using tf.gather(..., axis=1). We have batches \n",
        "      # YOUR CODE HERE  reshape to original shape\n",
        "\n",
        "    # Exercise 4: data augmentation as self-supervision signal; for every image \n",
        "    # in the batch, sample uniformly at random a transformation (rotation), \n",
        "    # and apply it to the image while returning the id of the transformation\n",
        "    label_transf = []\n",
        "    if flag_selfsup and num_transf:\n",
        "      list_img = []\n",
        "      for i in xrange(BATCH_SIZE_TRAIN):\n",
        "        ################\n",
        "        # YOUR CODE HERE get a transformation label_ = tf.random.uniform...\n",
        "        # YOUR CODE HERE apply transformation img = tf.image.rot90(image[i], k=label_)\n",
        "        label_transf.append(label_)\n",
        "        list_img.append(img)\n",
        "      image = tf.stack(list_img, axis=0)\n",
        "      label_transf = tf.stack(label_transf, axis=0)\n",
        "    return image, label_transf\n",
        "  return fn\n",
        "\n",
        "def test_image_preprocess():\n",
        "  def fn(image):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    image = image * 2 - 1\n",
        "    if flag_permute:\n",
        "      ################\n",
        "      # YOUR CODE HERE do the same as for training\n",
        "      p = get_permutation_cifar10()\n",
        "    else:\n",
        "      sh = image.get_shape()\n",
        "      image = tf.reshape(image, [BATCH_SIZE_TEST, sh[1], sh[2], sh[3]])\n",
        "    return image\n",
        "  return fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OalRJVrVR2up",
        "colab_type": "text"
      },
      "source": [
        "## Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRsh0ZUeV6m2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define parameters of resnet blocks for two resnet models\n",
        "ResNetBlockParams = collections.namedtuple(\n",
        "    \"ResNetBlockParams\", [\"output_channels\", \"bottleneck_channels\", \"stride\"])\n",
        "\n",
        "BLOCKS_50 = (\n",
        "    (ResNetBlockParams(256, 64, 1),) * 2 + (ResNetBlockParams(256, 64, 2),),\n",
        "    (ResNetBlockParams(512, 128, 1),) * 3 + (ResNetBlockParams(512, 128, 2),),\n",
        "    (ResNetBlockParams(1024, 256, 1),) * 5 + (ResNetBlockParams(1024, 256, 2),),\n",
        "    (ResNetBlockParams(2048, 512, 1),) * 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxkKmkC3WLt8",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Utils\n",
        "\n",
        "def _fixed_padding(inputs, kernel_size):\n",
        "  \"\"\"Pads the input along the spatial dimensions.\"\"\"\n",
        "  pad_total = kernel_size - 1\n",
        "  pad_begin = pad_total // 2\n",
        "  pad_end = pad_total - pad_begin\n",
        "  padded_inputs = tf.pad(inputs, [[0, 0], [pad_begin, pad_end],\n",
        "                                  [pad_begin, pad_end], [0, 0]])\n",
        "  return padded_inputs\n",
        "\n",
        "def _max_pool2d_same(inputs, kernel_size, stride, padding):\n",
        "  \"\"\"Strided 2-D max-pooling with fixed padding. \n",
        "  When padding='SAME' and stride > 1, we do fixed zero-padding followed by \n",
        "  max_pool2d with 'VALID' padding.\"\"\"\n",
        "\n",
        "  if padding == \"SAME\" and stride > 1:\n",
        "    padding = \"VALID\"\n",
        "    inputs = _fixed_padding(inputs, kernel_size)\n",
        "  return tf.layers.MaxPooling2D(kernel_size, strides=stride, padding=padding)(inputs)\n",
        "\n",
        "def _conv2d_same(inputs, num_outputs, kernel_size, stride, use_bias=False,\n",
        "                 name=\"conv_2d_same\"):\n",
        "  \"\"\"Strided 2-D convolution with 'SAME' padding. If stride > 1, we do fixed\n",
        "  zero-padding, followed by conv2d with 'VALID' padding.\"\"\"\n",
        "  if stride == 1:\n",
        "    padding = \"SAME\"\n",
        "  else:\n",
        "    padding = \"VALID\"\n",
        "    inputs = _fixed_padding(inputs, kernel_size)\n",
        "\n",
        "  return tf.layers.Conv2D(num_outputs, kernel_size, strides=stride,\n",
        "                          padding=padding, use_bias=use_bias, name=name)(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVYFesDOeRKX",
        "colab_type": "text"
      },
      "source": [
        "### [Resnet Block V2](https://arxiv.org/pdf/1603.05027.pdf) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAUiEMH7VMih",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://github.com/eeml2019/PracticalSessions/blob/master/assets/bottleneck.png?raw=true)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xby5GIFGaIEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exercise 1: define resnet block v2\n",
        "def resnet_block(inputs, output_channels, bottleneck_channels, stride,\n",
        "                 training=None, name=\"resnet_block\"):\n",
        "  \"\"\"Create a resnet block.\"\"\"\n",
        "  num_input_channels = inputs.get_shape()[-1]\n",
        "  batch_norm_args = {\n",
        "      \"training\": training\n",
        "      }\n",
        "  # ResNet V2 uses pre-activation, where the batch norm and relu are before\n",
        "  # convolutions, rather than after as in ResNet V1.\n",
        "  preact = tf.layers.BatchNormalization(name=name+\"/bn_preact\")(inputs,\n",
        "                                                                **batch_norm_args)\n",
        "  preact = tf.nn.relu(preact)\n",
        "\n",
        "  if output_channels == num_input_channels:\n",
        "    # Use subsampling to match output size.\n",
        "    # Note we always use `inputs` in this case, not `preact`.\n",
        "    if stride == 1:\n",
        "      shortcut = inputs\n",
        "    else:\n",
        "      shortcut = _max_pool2d_same(inputs, 1, stride=stride, padding=\"SAME\")\n",
        "  else:\n",
        "    # Use 1x1 convolution shortcut to increase channels to `output_channels`.\n",
        "    ################\n",
        "    # YOUR CODE HERE shortcut = tf.layers.Conv2D\n",
        "\n",
        "  # add the 3 residual subunits: conv + batchnorm + relu\n",
        "  # subunit 1\n",
        "  ################\n",
        "  # YOUR CODE HERE residual = tf.layers.Conv2D...\n",
        "  # YOUR CODE HERE residual = tf.layers.BatchNormalization...\n",
        "  # YOUR CODE HERE residual = tf.nn.relu...\n",
        "  \n",
        "  # subunit 2\n",
        "  ################\n",
        "  # YOUR CODE HERE residual = _conv2d_same\n",
        "  # YOUR CODE HERE residual = tf.layers.BatchNormalization...\n",
        "  # YOUR CODE HERE residual = tf.nn.relu...\n",
        "\n",
        "  # subunit 3\n",
        "  ################\n",
        "  # YOUR CODE HERE residual = tf.layers.Conv2D...\n",
        "  # YOUR CODE HERE residual = tf.layers.BatchNormalization...\n",
        "  # YOUR CODE HERE residual = tf.nn.relu...\n",
        "  \n",
        "  # add residual to shortcut\n",
        "  output = shortcut + residual\n",
        "\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFrYIsi1aUEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# stack resnet blocks\n",
        "def _build_resnet_blocks(inputs, blocks, batch_norm_args):\n",
        "  \"\"\"Connects the resnet block into the graph.\"\"\"\n",
        "  outputs = []\n",
        "\n",
        "  for num, subblocks in enumerate(blocks):\n",
        "    with tf.variable_scope(\"block_{}\".format(num)):\n",
        "      for i, block in enumerate(subblocks):\n",
        "        args = {\n",
        "            \"name\": \"resnet_block_{}\".format(i)\n",
        "        }\n",
        "        args.update(block._asdict())\n",
        "        args.update(batch_norm_args)\n",
        "        inputs = resnet_block(inputs, **args)\n",
        "        outputs += [inputs]\n",
        "\n",
        "  return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUTHMi2DcF89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define full architecture: input convs, resnet blocks, output classifier\n",
        "def resnet_v2(inputs, blocks, is_training=True,\n",
        "              num_classes=10, num_transf=None, use_global_pool=True, \n",
        "              name=\"resnet_v2\"):\n",
        "  \"\"\"ResNet V2.\"\"\"\n",
        "  blocks = tuple(blocks)\n",
        "\n",
        "  batch_norm_args = {\n",
        "      \"training\": is_training\n",
        "  }\n",
        "\n",
        "  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "    # Add initial non-resnet conv layer and max_pool\n",
        "    inputs = _conv2d_same(inputs, 64, 7, stride=2, name=\"root\")\n",
        "    inputs = _max_pool2d_same(inputs, 3, stride=2, padding=\"SAME\")\n",
        "\n",
        "    # Stack resnet blocks\n",
        "    resnet_outputs = _build_resnet_blocks(inputs, blocks, batch_norm_args)\n",
        "    # Take the activations of the last resnet block.\n",
        "    inputs = resnet_outputs[-1]\n",
        "    inputs = tf.layers.BatchNormalization(name=\"bn_postnorm\")(inputs,\n",
        "                                                              **batch_norm_args)\n",
        "    inputs = tf.nn.relu(inputs)\n",
        "    if use_global_pool:\n",
        "      inputs = tf.reduce_mean(inputs, [1, 2], name=\"use_global_pool\",\n",
        "                              keepdims=True)\n",
        "\n",
        "    # Add output classifier\n",
        "    logits = tf.layers.Conv2D(num_classes, 1, name=\"logits\")(inputs)\n",
        "    logits = tf.squeeze(inputs, axis=[1, 2])\n",
        "    \n",
        "    # Add second head for transformation prediction\n",
        "    logits_transf = None\n",
        "    if num_transf and flag_selfsup:\n",
        "      pass\n",
        "      ################\n",
        "      # YOUR CODE HERE Exercise 4\n",
        "      # YOUR CODE HERE logits_transf = tf.layers.Conv2D...\n",
        "      # YOUR CODE HERE logits_transf = tf.squeeze...\n",
        "\n",
        "  return (logits, logits_transf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gcsY1Mjaf_s",
        "colab_type": "text"
      },
      "source": [
        "## Define simple MLP baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYekdfZBaiTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp(inputs, num_classes=10, num_transf=None, is_training=True, name=\"mlp\"):\n",
        "  batch_norm_args = {\n",
        "      \"training\": is_training\n",
        "  }\n",
        "  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "    bs = inputs.get_shape().as_list()[0]\n",
        "    inputs = tf.reshape(inputs, [bs, -1])\n",
        "    net = tf.layers.dense(inputs, 1024)\n",
        "    net = tf.nn.relu(net)\n",
        "    net = tf.layers.BatchNormalization(name=\"bn_postnorm1\")(inputs, **batch_norm_args)\n",
        "    net = tf.layers.dense(net, 1024)\n",
        "    net = tf.nn.relu(net)\n",
        "    net = tf.layers.BatchNormalization(name=\"bn_postnorm2\")(net, **batch_norm_args)\n",
        "    logits = tf.layers.dense(net, num_classes, name=\"logits\")\n",
        "    logits_transf = None\n",
        "    if num_transf:\n",
        "      logits_transf = tf.layers.dense(net, num_transf, name=\"logits_transf\")\n",
        "    return logits, logits_transf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPex0rz3auId",
        "colab_type": "text"
      },
      "source": [
        "## Set up training pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoTsOIRQSPV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First define the preprocessing ops for the train/test data\n",
        "crop_height = 32 #@param \n",
        "crop_width = 32 #@param\n",
        "# NUM_TRANSF can be None or 4 corresponding to 4 rotations (0, 90, 180, 270)\n",
        "NUM_TRANSF = 4 #@param  \n",
        "preprocess_fn_train = train_image_preprocess(crop_height, crop_width, NUM_TRANSF)\n",
        "preprocess_fn_test = test_image_preprocess()\n",
        "NUM_CLASSES = 10 #@param"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "117ebPugarCO",
        "colab_type": "text"
      },
      "source": [
        "### Get predictions from either MLP baseline or convnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfHEpqp3DZbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "blocks = BLOCKS_50\n",
        "inp_train, labels_selfsup = preprocess_fn_train(batch_train_images)\n",
        "inp_test = preprocess_fn_test(batch_test_images)\n",
        "\n",
        "if model == 'mlp':\n",
        "  train_predictions, logits_selfsup = mlp(inp_train, num_classes=NUM_CLASSES,\n",
        "                                          num_transf=NUM_TRANSF, is_training=True)\n",
        "  test_predictions, _ = mlp(inp_test, num_classes=NUM_CLASSES,\n",
        "                            num_transf=NUM_TRANSF, is_training=False)\n",
        "else:  # model is resnet_v2\n",
        "  train_predictions, logits_selfsup = resnet_v2(inp_train, blocks,\n",
        "                                                num_classes=NUM_CLASSES,\n",
        "                                                num_transf=NUM_TRANSF,\n",
        "                                                is_training=True)\n",
        "  test_predictions, _ = resnet_v2(inp_test, blocks, \n",
        "                                  num_classes=NUM_CLASSES,\n",
        "                                  num_transf=NUM_TRANSF, is_training=False)\n",
        "print(train_predictions)\n",
        "print(logits_selfsup)\n",
        "print(test_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-F4W5niV1sm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get number of parameters in a scope by iterating through the trainable variables\n",
        "def get_num_params(scope):\n",
        "  total_parameters = 0\n",
        "  for variable in tf.trainable_variables(scope):\n",
        "    # shape is an array of tf.Dimension\n",
        "    shape = variable.get_shape()\n",
        "    variable_parameters = 1\n",
        "    for dim in shape:\n",
        "      variable_parameters *= dim.value\n",
        "    total_parameters += variable_parameters\n",
        "  return total_parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7VKCh9ySddK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get number of parameters in the model.\n",
        "print (\"Total number of parameters of models\")\n",
        "print (get_num_params(\"resnet_v2\"))\n",
        "print (get_num_params(\"mlp\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSh0bFEGSgJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classification loss using cross entropy\n",
        "def classification_loss(logits=None, labels=None):\n",
        "  # We reduce over batch dimension, to ensure the loss is a scalar.   \n",
        "  return tf.reduce_mean(\n",
        "      tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "          labels=labels, logits=logits))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPE9TfTY1MB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# l2 regularization on the weights\n",
        "def regularization_loss(l2_regularization=1e-4):\n",
        "  \"\"\"Provides regularization loss if it is enabled.\"\"\"\n",
        "\n",
        "  if tf.trainable_variables() and (l2_regularization > 0):\n",
        "    l2_reg = tf.contrib.layers.l2_regularizer(l2_regularization)\n",
        "    reg_losses = map(l2_reg, tf.trainable_variables())\n",
        "    return tf.add_n(reg_losses, name='regularization_loss')\n",
        "  else:\n",
        "    return tf.constant(0.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuiYAELn_RzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define train and test loss functions\n",
        "train_loss = classification_loss(labels=batch_train_labels, logits=train_predictions)\n",
        "test_loss = classification_loss(labels=batch_test_labels, logits=test_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNB-u-sH_v20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exercise 3 - Add regularization\n",
        "if flag_regularize is True:\n",
        "  pass\n",
        "  ################\n",
        "  # YOUR CODE HERE train_loss += ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFhHO_sgSjIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exercise 4: Add auxiliary loss for self-supervised learning; you can use the same classification_loss fn defined above\n",
        "if flag_selfsup:\n",
        "  pass\n",
        "  ################\n",
        "  # YOUR CODE HERE train_loss += ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXwpnrFWSmBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For evaluation, we look at top_k_accuracy since it's easier to interpret; normally k=1 or k=5\n",
        "def top_k_accuracy(k, labels, logits):\n",
        "  in_top_k = tf.nn.in_top_k(predictions=tf.squeeze(logits), targets=labels, k=k)\n",
        "  return tf.reduce_mean(tf.cast(in_top_k, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aUrDkAASwLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_optimizer(step):\n",
        "  \"\"\"Get the optimizer used for training.\"\"\"\n",
        "  lr_init = 0.01  # initial value for the learning rate\n",
        "  lr_schedule = (90e3, 100e3, 110e3) # after how many iterations to reduce the learning rate\n",
        "  lr_schedule = tf.cast(lr_schedule, tf.int64)\n",
        "  lr_factor = 0.1 # reduce learning rate by this factor\n",
        "  num_epochs = tf.reduce_sum(tf.cast(step >= lr_schedule, tf.float32))\n",
        "  lr = lr_init * lr_factor**num_epochs\n",
        "\n",
        "  return tf.train.MomentumOptimizer(learning_rate=lr, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_dTKQblSzkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a global step that is incremented during training; useful for e.g. learning rate annealing\n",
        "global_step = tf.train.get_or_create_global_step()\n",
        "\n",
        "# instantiate the optimizer\n",
        "optimizer = get_optimizer(global_step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEJhc61CS3Qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get training ops\n",
        "training_op = optimizer.minimize(train_loss, global_step)\n",
        "\n",
        "if flag_batch_norm == 'ON':\n",
        "  # Retrieve the update ops, which contain the moving average ops\n",
        "  update_ops = tf.group(*tf.get_collection(tf.GraphKeys.UPDATE_OPS))\n",
        "\n",
        "  # Manually add the update ops to the dependency path executed at each training iteration\n",
        "  training_op = tf.group(training_op, update_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lyl08omS6U3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get test ops\n",
        "test_acc_op = top_k_accuracy(1, batch_test_labels, test_predictions)\n",
        "train_acc_op = top_k_accuracy(1, batch_train_labels, train_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeHQMMqsS9Cz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that takes a list of losses and plots them.\n",
        "def plot_losses(loss_list, steps):\n",
        "  display.clear_output(wait=True)\n",
        "  display.display(pl.gcf())\n",
        "  pl.plot(steps, loss_list, c='b')\n",
        "  time.sleep(1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQBpZRP-TKI0",
        "colab_type": "text"
      },
      "source": [
        "### Define training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNtIcyk7S_ub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define number of training iterations and reporting intervals\n",
        "TRAIN_ITERS = 100e3 #@param\n",
        "REPORT_TRAIN_EVERY = 100 #@param\n",
        "PLOT_EVERY = 500 #@param\n",
        "REPORT_TEST_EVERY = 1000 #@param\n",
        "TEST_ITERS = 100 #@param"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ARGcbSGTFDN",
        "colab_type": "text"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSuV2dF-TDCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the session and initialize variables\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# Question: What is the accuracy of the model at iteration 0, i.e. before training starts? \n",
        "train_iter = 0\n",
        "losses = []\n",
        "steps = []\n",
        "for train_iter in range(int(TRAIN_ITERS)):\n",
        "  _, train_loss_np, inp_img, tr_lbl = sess.run([training_op, train_loss, inp_train, batch_train_labels])\n",
        "  \n",
        "  if (train_iter % REPORT_TRAIN_EVERY) == 0:\n",
        "    losses.append(train_loss_np)\n",
        "    steps.append(train_iter)\n",
        "  if (train_iter % PLOT_EVERY) == 0:\n",
        "    plot_losses(losses, steps)    \n",
        "    \n",
        "  if (train_iter % REPORT_TEST_EVERY) == 0:\n",
        "    avg_acc = 0.0\n",
        "    train_avg_acc = 0.0\n",
        "    for test_iter in range(TEST_ITERS):\n",
        "      acc, acc_train = sess.run([test_acc_op, train_acc_op])\n",
        "      avg_acc += acc\n",
        "      train_avg_acc += acc_train\n",
        "      \n",
        "    avg_acc /= (TEST_ITERS)\n",
        "    train_avg_acc /= (TEST_ITERS)\n",
        "    print ('Test acc at iter {0:5d} out of {1:5d} is {2:.2f}%'.format(int(train_iter), int(TRAIN_ITERS), avg_acc*100.0))\n",
        "    # print ('Train acc at iter {0:5d} out of {1:5d} is {2:.2f}%'.format(int(train_iter), int(TRAIN_ITERS), train_avg_acc*100.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuOOlirq0tgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}